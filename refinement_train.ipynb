{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597011011413",
   "display_name": "Python 3.7.7 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from PIL import Image\n",
    "from stylegan2.utils import postprocess_images, adjust_dynamic_range\n",
    "from stylegan2.generator import Generator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = tf.keras.models.load_model(\"C:/repos/gan-refinement/nets/lutz_new_classifier_tf1.14.h5\")\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w = np.abs(np.mean(model.trainable_weights[0].numpy().reshape((1024, 1024, 3)), axis=-1))\n",
    "# w = np.clip(w, 0, np.quantile(w, 0.999))\n",
    "# plt.axis(\"off\")\n",
    "# plt.imshow(w, cmap=plt.cm.inferno)\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_DIR = \"D:/datasets/adv_images_eps32\"\n",
    "RESULT_DIR = \"models/\"\n",
    "assert os.path.isdir(IMAGES_DIR) and os.path.isdir(RESULT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS           = 20\n",
    "BATCH_SIZE       = 4\n",
    "BATCH_PER_GPU    = 4\n",
    "VALIDATION_SPLIT = 0.2\n",
    "\n",
    "AUTOTUNE         = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "assert BATCH_SIZE % BATCH_PER_GPU == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(g_params):\n",
    "    ### Taken from inference_from_official_weights.py\n",
    "    # prepare variables & construct generator\n",
    "    \n",
    "    g_clone = Generator(g_params)\n",
    "\n",
    "    # finalize model (build)\n",
    "    test_latent = np.ones((1, g_params['z_dim']), dtype=np.float32)\n",
    "    test_labels = np.ones((1, g_params['labels_dim']), dtype=np.float32)\n",
    "    _ = g_clone([test_latent, None], training=False)\n",
    "    _ = g_clone([test_latent, None], training=True)\n",
    "\n",
    "    # restore\n",
    "    ckpt_dir = './official-converted'\n",
    "    ckpt = tf.train.Checkpoint(g_clone=g_clone)\n",
    "    manager = tf.train.CheckpointManager(ckpt, ckpt_dir, max_to_keep=1)\n",
    "    ckpt.restore(manager.latest_checkpoint)\n",
    "    if manager.latest_checkpoint:\n",
    "        print('Restored from {}'.format(manager.latest_checkpoint))\n",
    "\n",
    "    return g_clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_params = {\n",
    "        'z_dim': 512,\n",
    "        'w_dim': 512,\n",
    "        'labels_dim': 0,\n",
    "        'n_mapping': 8,\n",
    "        'resolutions': [4, 8, 16, 32, 64, 128, 256, 512, 1024],\n",
    "        'featuremaps': [512, 512, 512, 512, 512, 256, 128, 64, 32],\n",
    "        'w_ema_decay': 0.995,\n",
    "        'style_mixing_prob': 0.0,\n",
    "        'randomize_noise': False,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Restored from ./official-converted\\ckpt-0\nModel: \"generator\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ng_mapping (Mapping)          multiple                  2101248   \n_________________________________________________________________\nlambda_1 (Lambda)            multiple                  0         \n_________________________________________________________________\ng_synthesis (Synthesis)      multiple                  28268812  \n=================================================================\nTotal params: 30,370,572\nTrainable params: 30,370,060\nNon-trainable params: 512\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "generator = build_generator(g_params)\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image(seed, generator, latent_dim):\n",
    "    rnd = np.random.RandomState(seed)\n",
    "    latents = rnd.randn(1, latent_dim).astype(np.float32)\n",
    "    image_out, _ = generator([latents, None], training=False, truncation_psi=1.0)\n",
    "    image_out = postprocess_images(image_out).numpy()\n",
    "    return image_out[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_save_images(save_path, generator, latent_dim, num_images=10_000, start_seed=0):\n",
    "    assert os.path.isdir(save_path)\n",
    "\n",
    "    for idx, seed in enumerate(range(0, num_images)):\n",
    "        image = generate_image(seed, generator,latent_dim)\n",
    "        Image.fromarray(image, 'RGB').save(os.path.join(save_path, f'seed{seed:05d}.png'))\n",
    "        print(f\"\\rImage {idx + 1}/{num_images}\", end=\"\")\n",
    "\n",
    "# generate_save_images(\"D:/datasets/test_images\", generator, g_params[\"z_dim\"], num_images=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_from_path(path, latent_dim):\n",
    "    name = os.path.splitext(os.path.basename(path))[0]\n",
    "    seed = int(name.split(\"seed\")[1])\n",
    "    rand = np.random.RandomState(seed)\n",
    "    return rand.randn(latent_dim).astype(np.float32)\n",
    "\n",
    "image_paths = glob(os.path.join(IMAGES_DIR, \"*.png\"))\n",
    "noise_np = np.asarray([noise_from_path(path, g_params[\"z_dim\"]) for path in image_paths])\n",
    "assert len(image_paths) == len(noise_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Image shape is assumed as (1024, 1024, 3)\n"
    }
   ],
   "source": [
    "image_shape = 2 * (g_params[\"resolutions\"][-1],) + (3,)\n",
    "print(f\"Image shape is assumed as {image_shape}\")\n",
    "\n",
    "def process_sample(noise, path):\n",
    "    # Load image\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.io.decode_image(image)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image.set_shape(image_shape) # fix tensorflow issue 24520\n",
    "\n",
    "    # Preprocess to net input range [-1, 1]\n",
    "    image = adjust_dynamic_range(image, range_in=(0.0, 255.0), range_out=(-1.0, 1.0), out_dtype=tf.dtypes.float32)\n",
    "    image = tf.transpose(image, [2, 0, 1])\n",
    "\n",
    "    return noise, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(TensorSpec(shape=(512,), dtype=tf.float32, name=None),\n TensorSpec(shape=(), dtype=tf.string, name=None))"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((noise_np, image_paths))\n",
    "dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_dataset(dataset, grid=(4,4)):\n",
    "    assert len(grid) == 2 and isinstance(grid, (tuple, list)) and grid[1] % 2 == 0   \n",
    "    nois, imgs = next(iter(dataset.batch(8)))\n",
    "    gens, _ = generator([nois, None], training=False)\n",
    "    gens = postprocess_images(gens).numpy()\n",
    "    imgs = postprocess_images(imgs).numpy()\n",
    "\n",
    "    num_pairs = grid[0]*grid[1] // 2\n",
    "    assert num_pairs <= gens.shape[0]\n",
    "\n",
    "    plt.figure(figsize=(grid[0] * 2, grid[1] * 2))\n",
    "    for idx in range(num_pairs):\n",
    "        plt.subplot(4, 4, idx * 2 + 1)\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(gens[idx], cmap=\"gray\")\n",
    "\n",
    "        plt.subplot(4, 4, idx * 2 + 2)\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(imgs[idx], cmap=\"gray\")\n",
    "\n",
    "# test_dataset(dataset.map(process_sample, AUTOTUNE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(TensorSpec(shape=(None, 512), dtype=tf.float32, name=None),\n TensorSpec(shape=(None, 3, 1024, 1024), dtype=tf.float32, name=None))"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "TRAIN_SIZE = 1000#len(image_paths)\n",
    "VAL_SIZE = 200\n",
    "\n",
    "train_dataset = dataset.take(TRAIN_SIZE).shuffle(TRAIN_SIZE).map(process_sample, AUTOTUNE).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "train_dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = dataset.skip(TRAIN_SIZE).take(VAL_SIZE).shuffle(VAL_SIZE).map(process_sample, AUTOTUNE).batch(BATCH_SIZE).prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['g_mapping/dense_0/w:0',\n 'g_mapping/dense_1/w:0',\n 'g_mapping/dense_2/w:0',\n 'g_mapping/dense_3/w:0',\n 'g_mapping/dense_4/w:0',\n 'g_mapping/dense_5/w:0',\n 'g_mapping/dense_6/w:0',\n 'g_mapping/dense_7/w:0',\n 'g_mapping/bias_0/b:0',\n 'g_mapping/bias_1/b:0',\n 'g_mapping/bias_2/b:0',\n 'g_mapping/bias_3/b:0',\n 'g_mapping/bias_4/b:0',\n 'g_mapping/bias_5/b:0',\n 'g_mapping/bias_6/b:0',\n 'g_mapping/bias_7/b:0',\n 'g_synthesis/4x4/const/const:0',\n 'g_synthesis/4x4/const/conv/w:0',\n 'g_synthesis/4x4/const/conv/mod_dense/w:0',\n 'g_synthesis/4x4/const/conv/mod_bias/b:0',\n 'g_synthesis/4x4/const/noise/w:0',\n 'g_synthesis/4x4/const/bias/b:0',\n 'g_synthesis/4x4/ToRGB/conv/w:0',\n 'g_synthesis/4x4/ToRGB/conv/mod_dense/w:0',\n 'g_synthesis/4x4/ToRGB/conv/mod_bias/b:0',\n 'g_synthesis/4x4/ToRGB/bias/b:0',\n 'g_synthesis/8x8/block/conv_0/w:0',\n 'g_synthesis/8x8/block/conv_0/mod_dense/w:0',\n 'g_synthesis/8x8/block/conv_0/mod_bias/b:0',\n 'g_synthesis/8x8/block/noise_0/w:0',\n 'g_synthesis/8x8/block/bias_0/b:0',\n 'g_synthesis/8x8/block/conv_1/w:0',\n 'g_synthesis/8x8/block/conv_1/mod_dense/w:0',\n 'g_synthesis/8x8/block/conv_1/mod_bias/b:0',\n 'g_synthesis/8x8/block/noise_1/w:0',\n 'g_synthesis/8x8/block/bias_1/b:0',\n 'g_synthesis/16x16/block/conv_0/w:0',\n 'g_synthesis/16x16/block/conv_0/mod_dense/w:0',\n 'g_synthesis/16x16/block/conv_0/mod_bias/b:0',\n 'g_synthesis/16x16/block/noise_0/w:0',\n 'g_synthesis/16x16/block/bias_0/b:0',\n 'g_synthesis/16x16/block/conv_1/w:0',\n 'g_synthesis/16x16/block/conv_1/mod_dense/w:0',\n 'g_synthesis/16x16/block/conv_1/mod_bias/b:0',\n 'g_synthesis/16x16/block/noise_1/w:0',\n 'g_synthesis/16x16/block/bias_1/b:0',\n 'g_synthesis/32x32/block/conv_0/w:0',\n 'g_synthesis/32x32/block/conv_0/mod_dense/w:0',\n 'g_synthesis/32x32/block/conv_0/mod_bias/b:0',\n 'g_synthesis/32x32/block/noise_0/w:0',\n 'g_synthesis/32x32/block/bias_0/b:0',\n 'g_synthesis/32x32/block/conv_1/w:0',\n 'g_synthesis/32x32/block/conv_1/mod_dense/w:0',\n 'g_synthesis/32x32/block/conv_1/mod_bias/b:0',\n 'g_synthesis/32x32/block/noise_1/w:0',\n 'g_synthesis/32x32/block/bias_1/b:0',\n 'g_synthesis/64x64/block/conv_0/w:0',\n 'g_synthesis/64x64/block/conv_0/mod_dense/w:0',\n 'g_synthesis/64x64/block/conv_0/mod_bias/b:0',\n 'g_synthesis/64x64/block/noise_0/w:0',\n 'g_synthesis/64x64/block/bias_0/b:0',\n 'g_synthesis/64x64/block/conv_1/w:0',\n 'g_synthesis/64x64/block/conv_1/mod_dense/w:0',\n 'g_synthesis/64x64/block/conv_1/mod_bias/b:0',\n 'g_synthesis/64x64/block/noise_1/w:0',\n 'g_synthesis/64x64/block/bias_1/b:0',\n 'g_synthesis/128x128/block/conv_0/w:0',\n 'g_synthesis/128x128/block/conv_0/mod_dense/w:0',\n 'g_synthesis/128x128/block/conv_0/mod_bias/b:0',\n 'g_synthesis/128x128/block/noise_0/w:0',\n 'g_synthesis/128x128/block/bias_0/b:0',\n 'g_synthesis/128x128/block/conv_1/w:0',\n 'g_synthesis/128x128/block/conv_1/mod_dense/w:0',\n 'g_synthesis/128x128/block/conv_1/mod_bias/b:0',\n 'g_synthesis/128x128/block/noise_1/w:0',\n 'g_synthesis/128x128/block/bias_1/b:0',\n 'g_synthesis/256x256/block/conv_0/w:0',\n 'g_synthesis/256x256/block/conv_0/mod_dense/w:0',\n 'g_synthesis/256x256/block/conv_0/mod_bias/b:0',\n 'g_synthesis/256x256/block/noise_0/w:0',\n 'g_synthesis/256x256/block/bias_0/b:0',\n 'g_synthesis/256x256/block/conv_1/w:0',\n 'g_synthesis/256x256/block/conv_1/mod_dense/w:0',\n 'g_synthesis/256x256/block/conv_1/mod_bias/b:0',\n 'g_synthesis/256x256/block/noise_1/w:0',\n 'g_synthesis/256x256/block/bias_1/b:0',\n 'g_synthesis/512x512/block/conv_0/w:0',\n 'g_synthesis/512x512/block/conv_0/mod_dense/w:0',\n 'g_synthesis/512x512/block/conv_0/mod_bias/b:0',\n 'g_synthesis/512x512/block/noise_0/w:0',\n 'g_synthesis/512x512/block/bias_0/b:0',\n 'g_synthesis/512x512/block/conv_1/w:0',\n 'g_synthesis/512x512/block/conv_1/mod_dense/w:0',\n 'g_synthesis/512x512/block/conv_1/mod_bias/b:0',\n 'g_synthesis/512x512/block/noise_1/w:0',\n 'g_synthesis/512x512/block/bias_1/b:0',\n 'g_synthesis/1024x1024/block/conv_0/w:0',\n 'g_synthesis/1024x1024/block/conv_0/mod_dense/w:0',\n 'g_synthesis/1024x1024/block/conv_0/mod_bias/b:0',\n 'g_synthesis/1024x1024/block/noise_0/w:0',\n 'g_synthesis/1024x1024/block/bias_0/b:0',\n 'g_synthesis/1024x1024/block/conv_1/w:0',\n 'g_synthesis/1024x1024/block/conv_1/mod_dense/w:0',\n 'g_synthesis/1024x1024/block/conv_1/mod_bias/b:0',\n 'g_synthesis/1024x1024/block/noise_1/w:0',\n 'g_synthesis/1024x1024/block/bias_1/b:0',\n 'g_synthesis/8x8/ToRGB/conv/w:0',\n 'g_synthesis/8x8/ToRGB/conv/mod_dense/w:0',\n 'g_synthesis/8x8/ToRGB/conv/mod_bias/b:0',\n 'g_synthesis/8x8/ToRGB/bias/b:0',\n 'g_synthesis/16x16/ToRGB/conv/w:0',\n 'g_synthesis/16x16/ToRGB/conv/mod_dense/w:0',\n 'g_synthesis/16x16/ToRGB/conv/mod_bias/b:0',\n 'g_synthesis/16x16/ToRGB/bias/b:0',\n 'g_synthesis/32x32/ToRGB/conv/w:0',\n 'g_synthesis/32x32/ToRGB/conv/mod_dense/w:0',\n 'g_synthesis/32x32/ToRGB/conv/mod_bias/b:0',\n 'g_synthesis/32x32/ToRGB/bias/b:0',\n 'g_synthesis/64x64/ToRGB/conv/w:0',\n 'g_synthesis/64x64/ToRGB/conv/mod_dense/w:0',\n 'g_synthesis/64x64/ToRGB/conv/mod_bias/b:0',\n 'g_synthesis/64x64/ToRGB/bias/b:0',\n 'g_synthesis/128x128/ToRGB/conv/w:0',\n 'g_synthesis/128x128/ToRGB/conv/mod_dense/w:0',\n 'g_synthesis/128x128/ToRGB/conv/mod_bias/b:0',\n 'g_synthesis/128x128/ToRGB/bias/b:0',\n 'g_synthesis/256x256/ToRGB/conv/w:0',\n 'g_synthesis/256x256/ToRGB/conv/mod_dense/w:0',\n 'g_synthesis/256x256/ToRGB/conv/mod_bias/b:0',\n 'g_synthesis/256x256/ToRGB/bias/b:0',\n 'g_synthesis/512x512/ToRGB/conv/w:0',\n 'g_synthesis/512x512/ToRGB/conv/mod_dense/w:0',\n 'g_synthesis/512x512/ToRGB/conv/mod_bias/b:0',\n 'g_synthesis/512x512/ToRGB/bias/b:0',\n 'g_synthesis/1024x1024/ToRGB/conv/w:0',\n 'g_synthesis/1024x1024/ToRGB/conv/mod_dense/w:0',\n 'g_synthesis/1024x1024/ToRGB/conv/mod_bias/b:0',\n 'g_synthesis/1024x1024/ToRGB/bias/b:0']"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "# Print names of all trainable variables\n",
    "[var.name for var in generator.trainable_variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Freezed mapping\nFreezed g_synthesis/4x4/const/const:0\nFreezed g_synthesis/4x4/const/conv/w:0\nFreezed g_synthesis/4x4/const/conv/mod_dense/w:0\nFreezed g_synthesis/4x4/const/conv/mod_bias/b:0\nFreezed g_synthesis/4x4/const/noise/w:0\nFreezed g_synthesis/4x4/const/bias/b:0\nFreezed g_synthesis/4x4/ToRGB/conv/w:0\nFreezed g_synthesis/4x4/ToRGB/conv/mod_dense/w:0\nFreezed g_synthesis/4x4/ToRGB/conv/mod_bias/b:0\nFreezed g_synthesis/4x4/ToRGB/bias/b:0\nFreezed g_synthesis/8x8/block/conv_0/w:0\nFreezed g_synthesis/8x8/block/conv_0/mod_dense/w:0\nFreezed g_synthesis/8x8/block/conv_0/mod_bias/b:0\nFreezed g_synthesis/8x8/block/noise_0/w:0\nFreezed g_synthesis/8x8/block/bias_0/b:0\nFreezed g_synthesis/8x8/block/conv_1/w:0\nFreezed g_synthesis/8x8/block/conv_1/mod_dense/w:0\nFreezed g_synthesis/8x8/block/conv_1/mod_bias/b:0\nFreezed g_synthesis/8x8/block/noise_1/w:0\nFreezed g_synthesis/8x8/block/bias_1/b:0\nFreezed g_synthesis/16x16/block/conv_0/w:0\nFreezed g_synthesis/16x16/block/conv_0/mod_dense/w:0\nFreezed g_synthesis/16x16/block/conv_0/mod_bias/b:0\nFreezed g_synthesis/16x16/block/noise_0/w:0\nFreezed g_synthesis/16x16/block/bias_0/b:0\nFreezed g_synthesis/16x16/block/conv_1/w:0\nFreezed g_synthesis/16x16/block/conv_1/mod_dense/w:0\nFreezed g_synthesis/16x16/block/conv_1/mod_bias/b:0\nFreezed g_synthesis/16x16/block/noise_1/w:0\nFreezed g_synthesis/16x16/block/bias_1/b:0\nFreezed g_synthesis/32x32/block/conv_0/w:0\nFreezed g_synthesis/32x32/block/conv_0/mod_dense/w:0\nFreezed g_synthesis/32x32/block/conv_0/mod_bias/b:0\nFreezed g_synthesis/32x32/block/noise_0/w:0\nFreezed g_synthesis/32x32/block/bias_0/b:0\nFreezed g_synthesis/32x32/block/conv_1/w:0\nFreezed g_synthesis/32x32/block/conv_1/mod_dense/w:0\nFreezed g_synthesis/32x32/block/conv_1/mod_bias/b:0\nFreezed g_synthesis/32x32/block/noise_1/w:0\nFreezed g_synthesis/32x32/block/bias_1/b:0\nFreezed g_synthesis/64x64/block/conv_0/w:0\nFreezed g_synthesis/64x64/block/conv_0/mod_dense/w:0\nFreezed g_synthesis/64x64/block/conv_0/mod_bias/b:0\nFreezed g_synthesis/64x64/block/noise_0/w:0\nFreezed g_synthesis/64x64/block/bias_0/b:0\nFreezed g_synthesis/64x64/block/conv_1/w:0\nFreezed g_synthesis/64x64/block/conv_1/mod_dense/w:0\nFreezed g_synthesis/64x64/block/conv_1/mod_bias/b:0\nFreezed g_synthesis/64x64/block/noise_1/w:0\nFreezed g_synthesis/64x64/block/bias_1/b:0\nFreezed g_synthesis/8x8/ToRGB/conv/w:0\nFreezed g_synthesis/8x8/ToRGB/conv/mod_dense/w:0\nFreezed g_synthesis/8x8/ToRGB/conv/mod_bias/b:0\nFreezed g_synthesis/8x8/ToRGB/bias/b:0\nFreezed g_synthesis/16x16/ToRGB/conv/w:0\nFreezed g_synthesis/16x16/ToRGB/conv/mod_dense/w:0\nFreezed g_synthesis/16x16/ToRGB/conv/mod_bias/b:0\nFreezed g_synthesis/16x16/ToRGB/bias/b:0\nFreezed g_synthesis/32x32/ToRGB/conv/w:0\nFreezed g_synthesis/32x32/ToRGB/conv/mod_dense/w:0\nFreezed g_synthesis/32x32/ToRGB/conv/mod_bias/b:0\nFreezed g_synthesis/32x32/ToRGB/bias/b:0\nFreezed g_synthesis/64x64/ToRGB/conv/w:0\nFreezed g_synthesis/64x64/ToRGB/conv/mod_dense/w:0\nFreezed g_synthesis/64x64/ToRGB/conv/mod_bias/b:0\nFreezed g_synthesis/64x64/ToRGB/bias/b:0\n66 variables were freezed\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "56"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "def freeze_vars(gen, freeze_layers, freeze_mapping=True, freeze_synthesis=False):\n",
    "    if freeze_mapping: gen.layers[0].trainable = False; print(\"Freezed mapping\")\n",
    "    if freeze_synthesis: gen.layers[2].trainable = False; print(\"Freezed synthesis\")\n",
    "    train_vars = []\n",
    "    for var in gen.trainable_variables:\n",
    "        if any(layer in var.name for layer in freeze_layers):\n",
    "            print(f\"Freezed {var.name}\")\n",
    "        else:\n",
    "            train_vars.append(var)\n",
    "    print(f\"{len(gen.trainable_variables) - len(train_vars)} variables were freezed\")\n",
    "    return train_vars\n",
    "\n",
    "trainable_variables = freeze_vars(generator, [\"4x4\", \"8x8\", \"16x16\", \"32x32\", \"64x64\"])\n",
    "len(trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_optimizer = tf.keras.optimizers.Adam(1e-3)\n",
    "mean_loss = tf.keras.metrics.Mean('train_loss', dtype=tf.float32)\n",
    "\n",
    "@tf.function\n",
    "def mean_squared_error(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.square(y_true - y_pred), axis=1) # [batch, c, h, w]\n",
    "\n",
    "@tf.function\n",
    "def mean_absolute_error(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.abs(y_true - y_pred), axis=1) # [batch, c, h, w]\n",
    "\n",
    "@tf.function\n",
    "def train_step(latents, target_images):\n",
    "    accumulated_gradients = []\n",
    "    rounds = BATCH_SIZE // BATCH_PER_GPU\n",
    "\n",
    "    for start in range(0, BATCH_SIZE, BATCH_PER_GPU):\n",
    "        end = start +  BATCH_PER_GPU\n",
    "\n",
    "        with tf.GradientTape() as g_tape:\n",
    "            # Forward pass\n",
    "            fake_images, _ = generator([latents[start:end], None], training=False) # Deactivate style mixing etc\n",
    "            fake_images = tf.clip_by_value(fake_images, -1., 1.)\n",
    "\n",
    "            # Loss\n",
    "            g_loss = mean_absolute_error(target_images[start:end], fake_images)\n",
    "        \n",
    "        # Gradient accumulation\n",
    "        g_gradients = g_tape.gradient(g_loss, trainable_variables)\n",
    "        if start == 0:\n",
    "            accumulated_gradients = g_gradients\n",
    "        else:\n",
    "            accumulated_gradients = [ac_grad + grad for ac_grad, grad in zip(accumulated_gradients, g_gradients)]\n",
    "\n",
    "        # Metric update\n",
    "        mean_loss.update_state(tf.reduce_mean(g_loss, axis=[1, 2]))\n",
    "\n",
    "    # Average accumulated gradients and apply\n",
    "    if rounds > 1: accumulated_gradients = [ac_grad/rounds for ac_grad in accumulated_gradients]\n",
    "    g_optimizer.apply_gradients(zip(accumulated_gradients, trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_val_loss = tf.keras.metrics.Mean('val_loss', dtype=tf.float32)\n",
    "\n",
    "def val_step(latents, target_images):\n",
    "    for start in range(0, BATCH_SIZE, BATCH_PER_GPU):\n",
    "        end = start +  BATCH_PER_GPU\n",
    "\n",
    "        # Forward pass\n",
    "        fake_images, _ = generator([latents[start:end], None], training=False) # Deactivate style mixing etc\n",
    "        fake_images = tf.clip_by_value(fake_images, -1., 1.)\n",
    "\n",
    "        # Loss\n",
    "        g_loss = mean_squared_error(target_images[start:end], fake_images)\n",
    "\n",
    "        # Metric update\n",
    "        mean_val_loss.update_state(tf.reduce_mean(g_loss, axis=[1, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# num_steps = tf.data.experimental.cardinality(val_dataset).numpy()\n",
    "# for step, (latents, images) in enumerate(val_dataset):\n",
    "#     val_step(latents, images)\n",
    "#     if step % 10 == 0: print(f\"\\r{step+10:04d}/{num_steps:04d} loss {mean_val_loss.result().numpy():.6f}\", end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    print(\"Starting training...\")\n",
    "    num_steps = tf.data.experimental.cardinality(train_dataset).numpy()\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        print(f\"{epoch+1:02d}/{EPOCHS:02d}\")\n",
    "        start = time.time()\n",
    "\n",
    "        for step, (latents, images) in enumerate(train_dataset):\n",
    "            train_step(latents, images)\n",
    "\n",
    "            if step % 10 == 0: print(f\"\\r{step:04d}/{num_steps:04d} loss {mean_loss.result().numpy():.6f}\", end=\"\")\n",
    "\n",
    "        print (f'\\r{time.time()-start:.3f} sec, avg loss {mean_loss.result().numpy():.6f}')\n",
    "        mean_loss.reset_states()\n",
    "        \n",
    "        # # Save the model every 10 epochs\n",
    "        # if (epoch + 1) % 10 == 0:\n",
    "        #     generator.save(os.path.join(SAVE_DIR, \"{:03d}_gen.h5\".format(epoch + 1)),\n",
    "        #         save_format=\"h5\")\n",
    "            \n",
    "        #     # Produce images for the GIF as we go\n",
    "        #     generate_images(epoch=epoch + 1)\n",
    "        # else:\n",
    "        #     generate_images()\n",
    "\n",
    "    # # Generate after the final epoch\n",
    "    # generate_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Starting training...\n01/20\n198.220 sec, avg loss 0.236826\n02/20\n0120/0250 loss 0.236913"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-2da0ffaf5447>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-22-c042ac94ed41>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlatents\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m             \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlatents\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m10\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"\\r{step:04d}/{num_steps:04d} loss {mean_loss.result().numpy():.6f}\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gan2\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gan2\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gan2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gan2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gan2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gan2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gan2\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}